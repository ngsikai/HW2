This is the README file for A0124828B and A0131188H's submission

== General Notes about this assignment ==

Place your comments or requests here for Min to read.  Discuss your
architecture or experiments in general.  A paragraph or two is usually
sufficient.

Indexing:
Each training file is broken down into sentences and then words using sent_tokenize() and word_tokenize() from nltk. Next, each word is stemmed using the PorterStemmer from nltk and changed to lowercase to form a token. For each training file, all its tokens are added to a set to ensure there are no repeated tokens. For each token in the set, the name (doc id) of the training file is appended to the postings list of the associated term. If the token is a new term in the dictionary, a postings list is created and the dictionary creates a new entry that points to the new postings list.

The dictionary is pickled while the postings lists are written line by line.

Searching:
Each query in the query file is passed through the shunting yard algorithm in shunting_yard.py to create a single Query object, which will contain two Query or Word objects (see objects.py!). The modified shunting yard algorithm also optimizes AND and OR queries according to the frequencies of the available operands.

The final Query object created will be unwrapped recursively in search.py, until the base case of a Word object is reached. The postings list of the Word object will then be read using seek() and read() functions. This recursive unwrapping will result in a series of merges, eventually producing the final postings list.

== Files included with this submission ==

List the files in your submission here and provide a short 1 line
description of each file.  Make sure your submission's files are named
and formatted correctly.

index.py
Program that takes in training data, index it and write out the dictionary and
postings lists created into two output files.

search.py
Program that takes in the dictionary file and postings list file generated by
index.py and outputs the results of given queries.

merge.py
Module that holds the logic of the merge functions used in search.py.

objects.py
Module that contains the logic behind the Word and Query classes used in shunting_yard.py.

shunting_yard.py
Module that contains the logic behind the modified shunting yard algorithm used
to process the boolean queries.

dictionary.txt
Text file that stores the pickled dictionary

postings.txt
Text file that stores the postings lists of doc ids in binary. 
Each doc id is represented by 15 bits and then a space.

README.txt
Descriptions of submitted files as well as Statement of individual work.

ESSAY.txt
Essay questions as part of the homework assignment.

== Statement of individual work ==

Please initial one of the following statements.

[x] We, A0124828B and A0131188H, certify that I have followed the CS 3245 Information Retrieval class guidelines for homework assignments.  In particular, I
expressly vow that I have followed the Facebook rule in discussing
with others in doing the assignment and did not take notes (digital or
printed) from the discussions.

[ ] We, A0124828B and A0131188H, did not follow the class rules regarding homework
assignment, because of the following reason:

<Please fill in>

I suggest that I should be graded as follows:

<Please fill in>

== References ==

<Please list any websites and/or people you consulted with for this
assignment and state their role>

Java Implementation of Boolean shunting yard algorithm that we adapted for our
shunting_yard.py
http://codereview.stackexchange.com/questions/89967/boolean-expressions-from-infix-to-postfix-notation-using-dijkstras-shunting-yar
